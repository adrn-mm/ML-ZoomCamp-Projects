{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this homework is to create a regression model for predicting housing prices (column 'median_house_value')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('housing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['ocean_proximity'].isin(['<1H OCEAN', 'INLAND'])]\n",
    "df.fillna(0, inplace=True)\n",
    "df['median_house_value'] = np.log1p(df['median_house_value'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=seed)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable from the features\n",
    "X_train = train_df.drop('median_house_value', axis=1)\n",
    "y_train = train_df['median_house_value']\n",
    "\n",
    "X_val = val_df.drop('median_house_value', axis=1)\n",
    "y_val = val_df['median_house_value']\n",
    "\n",
    "X_test = test_df.drop('median_house_value', axis=1)\n",
    "y_test = test_df['median_house_value']\n",
    "\n",
    "# Use DictVectorizer to turn the dataframes into matrices\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train.to_dict(orient='records'))\n",
    "X_val = vectorizer.transform(X_val.to_dict(orient='records'))\n",
    "X_test = vectorizer.transform(X_test.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature used for splitting the data is: ocean_proximity=<1H OCEAN\n"
     ]
    }
   ],
   "source": [
    "# Membuat model Decision Tree Regressor dengan max_depth=1\n",
    "model = DecisionTreeRegressor(max_depth=1)\n",
    "# Melatih model dengan data pelatihan\n",
    "model.fit(X_train, y_train)\n",
    "# Menentukan fitur yang digunakan untuk memisahkan data\n",
    "splitting_feature_index = model.tree_.feature[0]\n",
    "# Mengambil nama fitur berdasarkan indeksnya\n",
    "splitting_feature_name = vectorizer.get_feature_names_out()[splitting_feature_index]\n",
    "# Menampilkan fitur yang digunakan untuk pemisahan data\n",
    "print(\"The feature used for splitting the data is:\", splitting_feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation data: 0.23879635458921267\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor with the specified parameters\n",
    "rf_model = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "# Make predictions on the validation data\n",
    "y_val_pred = rf_model.predict(X_val)\n",
    "# Calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "print(\"RMSE on validation data:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=10: RMSE=0.23879635458921267\n",
      "n_estimators=20: RMSE=0.22998532813957734\n",
      "n_estimators=30: RMSE=0.22731461203509837\n",
      "n_estimators=40: RMSE=0.22664496313479962\n",
      "n_estimators=50: RMSE=0.22552369309511094\n",
      "n_estimators=60: RMSE=0.2252821217573416\n",
      "n_estimators=70: RMSE=0.22504562183085158\n",
      "n_estimators=80: RMSE=0.2247365597616832\n",
      "n_estimators=90: RMSE=0.224847020503133\n",
      "n_estimators=100: RMSE=0.2244994467707608\n",
      "n_estimators=110: RMSE=0.22431745023033342\n",
      "n_estimators=120: RMSE=0.22422840311713363\n",
      "n_estimators=130: RMSE=0.2240898677367095\n",
      "n_estimators=140: RMSE=0.22400076726350868\n",
      "n_estimators=150: RMSE=0.22383498377970573\n",
      "n_estimators=160: RMSE=0.22378489930483017\n",
      "n_estimators=170: RMSE=0.2237478751873627\n",
      "n_estimators=180: RMSE=0.22385252288931085\n",
      "n_estimators=190: RMSE=0.22385029061215883\n",
      "n_estimators=200: RMSE=0.22382483135925066\n",
      "The best value of n_estimators is 170 with RMSE=0.2237478751873627\n"
     ]
    }
   ],
   "source": [
    "# Define a range of n_estimators values to experiment with\n",
    "n_estimators_values = range(10, 201, 10)\n",
    "\n",
    "# Initialize an empty list to store RMSE values\n",
    "rmse_values = []\n",
    "\n",
    "for n_estimators in n_estimators_values:\n",
    "    # Create a Random Forest Regressor with the specified parameters\n",
    "    rf_model = RandomForestRegressor(n_estimators=n_estimators, random_state=1, n_jobs=-1)\n",
    "\n",
    "    # Train the model on the training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_val_pred = rf_model.predict(X_val)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "    rmse_values.append(rmse)\n",
    "    print(f\"n_estimators={n_estimators}: RMSE={rmse}\")\n",
    "\n",
    "# Find the index of the minimum RMSE value\n",
    "best_n_estimators_index = np.argmin(rmse_values)\n",
    "\n",
    "# Determine the best value of n_estimators\n",
    "best_n_estimators = n_estimators_values[best_n_estimators_index]\n",
    "print(f\"The best value of n_estimators is {best_n_estimators} with RMSE={rmse_values[best_n_estimators_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=10, n_estimators=10: RMSE=0.24353784467765577\n",
      "max_depth=10, n_estimators=20: RMSE=0.23966748097519688\n",
      "max_depth=10, n_estimators=30: RMSE=0.2375512511121298\n",
      "max_depth=10, n_estimators=40: RMSE=0.23707554234312792\n",
      "max_depth=10, n_estimators=50: RMSE=0.23648491199262234\n",
      "max_depth=10, n_estimators=60: RMSE=0.23658956920821567\n",
      "max_depth=10, n_estimators=70: RMSE=0.2365559006312253\n",
      "max_depth=10, n_estimators=80: RMSE=0.23589904741506867\n",
      "max_depth=10, n_estimators=90: RMSE=0.23575071677743767\n",
      "max_depth=10, n_estimators=100: RMSE=0.23563261988507686\n",
      "max_depth=10, n_estimators=110: RMSE=0.23547186347115812\n",
      "max_depth=10, n_estimators=120: RMSE=0.23542439491917747\n",
      "max_depth=10, n_estimators=130: RMSE=0.23533663804200974\n",
      "max_depth=10, n_estimators=140: RMSE=0.23516990186394524\n",
      "max_depth=10, n_estimators=150: RMSE=0.2350825414807882\n",
      "max_depth=10, n_estimators=160: RMSE=0.23509025390112293\n",
      "max_depth=10, n_estimators=170: RMSE=0.23502640247757595\n",
      "max_depth=10, n_estimators=180: RMSE=0.2351793077902451\n",
      "max_depth=10, n_estimators=190: RMSE=0.23507107288146775\n",
      "max_depth=10, n_estimators=200: RMSE=0.23512356374969787\n",
      "max_depth=15, n_estimators=10: RMSE=0.23852491978876308\n",
      "max_depth=15, n_estimators=20: RMSE=0.23053904529722308\n",
      "max_depth=15, n_estimators=30: RMSE=0.22821467212107185\n",
      "max_depth=15, n_estimators=40: RMSE=0.22744719166067237\n",
      "max_depth=15, n_estimators=50: RMSE=0.2263811674470673\n",
      "max_depth=15, n_estimators=60: RMSE=0.22620978173693848\n",
      "max_depth=15, n_estimators=70: RMSE=0.2261474804697244\n",
      "max_depth=15, n_estimators=80: RMSE=0.22582563722417903\n",
      "max_depth=15, n_estimators=90: RMSE=0.22588716618342075\n",
      "max_depth=15, n_estimators=100: RMSE=0.22556375902796827\n",
      "max_depth=15, n_estimators=110: RMSE=0.22537421839250962\n",
      "max_depth=15, n_estimators=120: RMSE=0.22523395071327015\n",
      "max_depth=15, n_estimators=130: RMSE=0.22517310250036407\n",
      "max_depth=15, n_estimators=140: RMSE=0.22504154656064762\n",
      "max_depth=15, n_estimators=150: RMSE=0.22485853061779776\n",
      "max_depth=15, n_estimators=160: RMSE=0.22478994955007298\n",
      "max_depth=15, n_estimators=170: RMSE=0.22469546477602909\n",
      "max_depth=15, n_estimators=180: RMSE=0.22483835437724942\n",
      "max_depth=15, n_estimators=190: RMSE=0.22483242094120187\n",
      "max_depth=15, n_estimators=200: RMSE=0.2248149526918283\n",
      "max_depth=20, n_estimators=10: RMSE=0.23769305470034555\n",
      "max_depth=20, n_estimators=20: RMSE=0.2299598641290254\n"
     ]
    }
   ],
   "source": [
    "# Define a range of max_depth and n_estimators values to experiment with\n",
    "max_depth_values = [10, 15, 20, 25]\n",
    "n_estimators_values = range(10, 201, 10)\n",
    "\n",
    "# Initialize variables to track the best max_depth and corresponding RMSE\n",
    "best_max_depth = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    for n_estimators in n_estimators_values:\n",
    "        # Create a Random Forest Regressor with the specified parameters\n",
    "        rf_model = RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators, random_state=1, n_jobs=-1)\n",
    "\n",
    "        # Train the model on the training data\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the validation data\n",
    "        y_val_pred = rf_model.predict(X_val)\n",
    "\n",
    "        # Calculate the RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "        # Check if this combination has a lower RMSE\n",
    "        if rmse < best_rmse:\n",
    "            best_max_depth = max_depth\n",
    "            best_rmse = rmse\n",
    "\n",
    "        print(f\"max_depth={max_depth}, n_estimators={n_estimators}: RMSE={rmse}\")\n",
    "\n",
    "print(f\"The best max_depth is {best_max_depth} with RMSE={best_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a Random Forest Regressor with the specified parameters\n",
    "rf_model = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances from the model\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a dictionary to map feature names to their importance scores\n",
    "feature_importance_dict = dict(zip(vectorizer.get_feature_names_out(), feature_importances))\n",
    "\n",
    "# Find the most important feature\n",
    "most_important_feature = max(feature_importance_dict, key=feature_importance_dict.get)\n",
    "\n",
    "print(\"The most important feature is:\", most_important_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Create DMatrix for train and validation\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Create a watchlist\n",
    "watchlist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "# Define XGBoost parameters\n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "    'eval_metric': 'rmse'  # RMSE as the evaluation metric\n",
    "}\n",
    "\n",
    "# Train the model with eta=0.3 for 100 rounds\n",
    "num_round = 100\n",
    "model_eta_0_3 = xgb.train(xgb_params, dtrain, num_round, watchlist)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred_eta_0_3 = model_eta_0_3.predict(dval)\n",
    "\n",
    "# Calculate RMSE for eta=0.3\n",
    "rmse_eta_0_3 = np.sqrt(mean_squared_error(y_val, y_val_pred_eta_0_3))\n",
    "print(\"RMSE with eta=0.3:\", rmse_eta_0_3)\n",
    "\n",
    "# Now change eta to 0.1\n",
    "xgb_params['eta'] = 0.1\n",
    "\n",
    "# Train the model with eta=0.1 for 100 rounds\n",
    "model_eta_0_1 = xgb.train(xgb_params, dtrain, num_round, watchlist)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred_eta_0_1 = model_eta_0_1.predict(dval)\n",
    "\n",
    "# Calculate RMSE for eta=0.1\n",
    "rmse_eta_0_1 = np.sqrt(mean_squared_error(y_val, y_val_pred_eta_0_1))\n",
    "print(\"RMSE with eta=0.1:\", rmse_eta_0_1)\n",
    "\n",
    "# Compare RMSE scores and identify the best eta\n",
    "if rmse_eta_0_3 < rmse_eta_0_1:\n",
    "    best_eta = 0.3\n",
    "elif rmse_eta_0_1 < rmse_eta_0_3:\n",
    "    best_eta = 0.1\n",
    "else:\n",
    "    best_eta = \"Both give equal value\"\n",
    "\n",
    "print(\"The best eta is:\", best_eta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

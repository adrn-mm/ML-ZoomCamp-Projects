{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKU77qsrW5PQ"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDkwPjy0W7gG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from urllib import request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCoohLerW8nu"
      },
      "source": [
        "# Download the Keras model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfLh55bdXADw"
      },
      "outputs": [],
      "source": [
        "model_url = \"https://github.com/alexeygrigorev/large-datasets/releases/download/wasps-bees/bees-wasps.h5\"\n",
        "keras_model_path = \"bees-wasps.h5\"\n",
        "tflite_model_path = \"bees-wasps.tflite\"\n",
        "\n",
        "# Download the Keras model\n",
        "request.urlretrieve(model_url, keras_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QRN3SFxXIp-"
      },
      "source": [
        "# Convert the Keras model to TF-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x45Oq8wcXNX8"
      },
      "outputs": [],
      "source": [
        "# Load the Keras model\n",
        "keras_model = tf.keras.models.load_model(keras_model_path)\n",
        "\n",
        "# Convert Keras model to TF-Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBAwRbUdXSnF"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Op7NLTeWsRt",
        "outputId": "1c70ec1b-da34-4f4b-f9f9-0a63604a8d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The size of the converted model is: 42.79 Mb\n"
          ]
        }
      ],
      "source": [
        "# Save the TF-Lite model\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Get the size of the converted model\n",
        "converted_model_size_mb = len(tflite_model) / (1024 * 1024)\n",
        "\n",
        "# Answer to Question 1\n",
        "print(f\"The size of the converted model is: {converted_model_size_mb:.2f} Mb\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_hJUhWtX31E"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUMM2FBcWvPa",
        "outputId": "e28477ad-62b4-433b-f5a9-2df164100126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output index for this model is: 13\n"
          ]
        }
      ],
      "source": [
        "# Print the details of the TF-Lite model\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input details\n",
        "input_index = interpreter.get_input_details()[0]['index']\n",
        "\n",
        "# Get output details\n",
        "output_details = interpreter.get_output_details()\n",
        "output_index = output_details[0]['index']\n",
        "\n",
        "# Answer to Question 2\n",
        "print(f\"The output index for this model is: {output_index}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv8ShJeXYC6L"
      },
      "source": [
        "# Preparing the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ-5ibjdYN8o",
        "outputId": "d781cf05-1fb0-4760-e3ef-97119b97cf50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4bC23IPX5V1",
        "outputId": "f658882f-5a87-420b-b63c-cb56697c5e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The target size for the image is: (224, 224)\n"
          ]
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "from urllib import request\n",
        "from PIL import Image\n",
        "\n",
        "def download_image(url):\n",
        "    with request.urlopen(url) as resp:\n",
        "        buffer = resp.read()\n",
        "    stream = BytesIO(buffer)\n",
        "    img = Image.open(stream)\n",
        "    return img\n",
        "\n",
        "def prepare_image(img, target_size):\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "    img = img.resize(target_size, Image.NEAREST)\n",
        "    return img\n",
        "\n",
        "# Download and resize the image\n",
        "image_url = \"https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg\"\n",
        "image = download_image(image_url)\n",
        "\n",
        "# Assume target size based on previous homework\n",
        "# Replace this with the correct target size if available\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Prepare the image\n",
        "resized_image = prepare_image(image, target_size)\n",
        "\n",
        "# Print the target size\n",
        "print(f\"The target size for the image is: {target_size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz3TLXWKYp4s"
      },
      "source": [
        "# Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QeFwmU_YWg9",
        "outputId": "2444e40d-006c-43b0-ef2b-75c8d38e024a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After pre-processing, the value in the first pixel, the R channel, is: 0.9215686\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert the resized image to a numpy array\n",
        "image_array = np.array(resized_image)\n",
        "\n",
        "# Pre-process the image array\n",
        "input_array = image_array / 255.0  # Normalize the pixel values to be between 0 and 1\n",
        "input_array = np.expand_dims(input_array, axis=0)  # Add batch dimension\n",
        "\n",
        "# Get the R channel value of the first pixel\n",
        "r_channel_value = input_array[0, 0, 0, 0]\n",
        "\n",
        "# Answer to Question 3\n",
        "print(f\"After pre-processing, the value in the first pixel, the R channel, is: {r_channel_value:.7f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYuuuqyHY6ne"
      },
      "source": [
        "# Question 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ijDm1-kZB6m",
        "outputId": "7f8c3f08-26bd-4e79-bea0-40508046143a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output of the model is: 0.659\n"
          ]
        }
      ],
      "source": [
        "# Load the TF-Lite model\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details\n",
        "input_tensor_index = interpreter.get_input_details()[0]['index']\n",
        "output_tensor_index = interpreter.get_output_details()[0]['index']\n",
        "\n",
        "# Set the input tensor\n",
        "interpreter.set_tensor(input_tensor_index, input_array.astype(np.float32))\n",
        "\n",
        "# Run the interpreter\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the output tensor\n",
        "model_output = interpreter.get_tensor(output_tensor_index)\n",
        "\n",
        "# Answer to Question 4\n",
        "print(f\"The output of the model is: {model_output[0][0]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 5\n",
        "![](https://i.imgur.com/rvpx5HT.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
